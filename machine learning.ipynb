{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model\n",
    "1. Make sure all packages are installed (WINDOWS)\n",
    "\n",
    "*    pip install numpy\n",
    "*   pip install pandas\n",
    "*   pip install os-sys\n",
    "*    pip install matplotlib\n",
    "*   pip install seaborn\n",
    "*   pip install scikit-learn\n",
    "*   pip install keras\n",
    "*   pip install tensorflow \n",
    "\n",
    "1. Make sure all packages are installed (MACS AND/OR ANACONDA ENVIRONMENT)\n",
    "*   conda  install numpy\n",
    "*   conda  install pandas\n",
    "*   conda  install os-sys\n",
    "*   conda  install matplotlib\n",
    "*   conda  install seaborn\n",
    "*   conda  install scikit-learn\n",
    "*   conda  install keras\n",
    "*   conda  install tensorflow \n",
    "\n",
    "Links:\n",
    "\n",
    "Kaggle Data: https://www.kaggle.com/harnoor343/fall-detection-accelerometer-data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Issues:\n",
    " * can I reshape before putting in LSTM layer :(\n",
    "\n",
    "Todo:\n",
    "* test script and sensordata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN IF YOU ARE NOT USING WINDOWS AND/OR NOT USING ANACONDA\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install os-sys\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install keras\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeviceOrientation\n",
      "AccelerationX\n",
      "AccelerationY\n",
      "AccelerationZ\n",
      "Label\n",
      "AccelerationX_fft\n",
      "AccelerationY_fft\n",
      "AccelerationZ_fft\n",
      "[0 1 3 2 4 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyuz\\AppData\\Local\\Temp\\ipykernel_11492\\162988833.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x = np.array(df.drop(['Label'], 1)) #drops row 'Label'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4432/4432 [==============================] - 29s 6ms/step - loss: 1.1253 - accuracy: 0.5550 - val_loss: 0.9022 - val_accuracy: 0.6528\n",
      "Epoch 2/10\n",
      "4432/4432 [==============================] - 28s 6ms/step - loss: 0.8592 - accuracy: 0.6678 - val_loss: 0.7907 - val_accuracy: 0.6945\n",
      "Epoch 3/10\n",
      "4432/4432 [==============================] - 27s 6ms/step - loss: 0.7980 - accuracy: 0.6870 - val_loss: 0.7688 - val_accuracy: 0.6958\n",
      "Epoch 4/10\n",
      "4432/4432 [==============================] - 27s 6ms/step - loss: 0.7711 - accuracy: 0.6967 - val_loss: 0.7425 - val_accuracy: 0.7089\n",
      "Epoch 5/10\n",
      "4432/4432 [==============================] - 28s 6ms/step - loss: 0.7528 - accuracy: 0.7041 - val_loss: 0.7483 - val_accuracy: 0.7021\n",
      "Epoch 6/10\n",
      "4432/4432 [==============================] - 27s 6ms/step - loss: 0.7395 - accuracy: 0.7084 - val_loss: 0.7175 - val_accuracy: 0.7160\n",
      "Epoch 7/10\n",
      "4432/4432 [==============================] - 27s 6ms/step - loss: 0.7299 - accuracy: 0.7115 - val_loss: 0.7084 - val_accuracy: 0.7188\n",
      "Epoch 8/10\n",
      "4432/4432 [==============================] - 28s 6ms/step - loss: 0.7211 - accuracy: 0.7158 - val_loss: 0.7081 - val_accuracy: 0.7198\n",
      "Epoch 9/10\n",
      "4432/4432 [==============================] - 28s 6ms/step - loss: 0.7162 - accuracy: 0.7186 - val_loss: 0.6996 - val_accuracy: 0.7225\n",
      "Epoch 10/10\n",
      "4432/4432 [==============================] - 28s 6ms/step - loss: 0.7076 - accuracy: 0.7200 - val_loss: 0.7005 - val_accuracy: 0.7222\n",
      "1900/1900 [==============================] - 4s 2ms/step - loss: 0.7005 - accuracy: 0.7222\n",
      "Test accuracy: 0.7221618890762329\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               66560     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,334\n",
      "Trainable params: 67,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141819, 7) (60780, 7, 1) (141819, 1) (60780, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import sklearn.model_selection\n",
    "\n",
    "#Yeah... that's all\n",
    "run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the entire machine learning model\n",
    "def run():\n",
    "    num = int(input(\"Choose a number from 1-3 to run the model with the correspdonding labels: \\n 1. runfall, downSit, freeFall, runSit, walkFall, walkSit \\n 2. runfall, downSit, freeFall, runSit, walkFall, walkSit, walkStand, walkWalk \\n 3. runfall, downSit, freeFall, runSit, walkFall, walkSit, walkStand, walkWalk, runRun, runStand, standStand, standWalk \\n\"))\n",
    "    df = data_collection(num)\n",
    "    df = data_normalize(df)\n",
    "    #data_plot(df)\n",
    "    df = data_categorical(df)\n",
    "    x_train, x_test, y_train, y_test = data_split(df)\n",
    "    model = model_create(x_train)\n",
    "    model = train_and_accurary_model(model, x_train, x_test, y_train, y_test)\n",
    "    model_save(model)\n",
    "\n",
    "    #debug purposes\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collection(num = 1):\n",
    "    # create a new directory called 'normalized', ignore it if it already exists\n",
    "    os.makedirs('./normalized', exist_ok=True)\n",
    "\n",
    "    all_labels = {1:['runfall', 'downSit', 'freeFall', 'runSit', 'walkFall', 'walkSit'], 2: ['runfall', 'downSit', 'freeFall', 'runSit', 'walkFall', 'walkSit', 'walkStand', 'walkWalk'], 3: ['runfall', 'downSit', 'freeFall', 'runSit', 'walkFall', 'walkSit', 'walkStand', 'walkWalk', 'runRun', 'runStand', 'standStand', 'standWalk']}\n",
    "    labels = all_labels[num]\n",
    "    for label in labels:\n",
    "        #read all csv files in the directory \"archive' + label, delimit by ';'\n",
    "        files = glob.glob('./archive/' + label + '/*.csv')\n",
    "        df = pd.concat([pd.read_csv(f, sep=';') for f in files], ignore_index=True)\n",
    "        # assign label to df column 'Label'\n",
    "        df['Label'] = label\n",
    "        # save columns 'DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label' to a new csv file\n",
    "        df[['DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label']].to_csv('./normalized/' + label + '.csv', index=False)\n",
    "        \n",
    "        \n",
    "    df = pd.concat([pd.read_csv(f) for f in glob.glob('./normalized/*.csv')], ignore_index = True)\n",
    "    return df\n",
    "\n",
    "def data_normalize(df):\n",
    "    # for each column in 'Accerlation', 'AccelerationY', 'AccelerationZ',\n",
    "    # add a new column that is the fft of the original column\n",
    "    for c in ['AccelerationX', 'AccelerationY', 'AccelerationZ']:\n",
    "        df[c + '_fft'] = np.fft.fft(df[c])\n",
    "\n",
    "    # debug purposes\n",
    "    for c in df.columns:\n",
    "        print(c)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def data_categorical(df):\n",
    "    # convert categorical data to numerical data\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    df['Label'] = df['Label'].cat.codes\n",
    "    print(df['Label'].unique())\n",
    "\n",
    "    # convert column `DeviceOrientation` to numerical data\n",
    "    df['DeviceOrientation'] = df['DeviceOrientation'].astype('category')\n",
    "    df['DeviceOrientation'] = df['DeviceOrientation'].cat.codes\n",
    "    return df\n",
    "\n",
    "def data_split(df):\n",
    "    x = np.array(df.drop(['Label'], 1)) #drops row 'Label'\n",
    "    y = np.array(df[\"Label\"])\n",
    "\n",
    "    #Spliting Data\n",
    "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.3)\n",
    "\n",
    "    # reshape training and testing data\n",
    "    y_train = np.array(y_train).reshape(-1,1) # (-1,1) because our data has a single feature, and a 'n' amount of rows\n",
    "    y_test = np.array(y_test).reshape(-1,1) # (-1,1) bec  ause our data has a single feature, and a 'n' amount of rows\n",
    "    x_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def model_create(x_train):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128, input_shape=(x_train.shape[1], 1)))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(6, activation='softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def train_and_accurary_model(model, x_train, x_test, y_train, y_test):\n",
    "  #reshape the features for the LSTM layer (I REALLY WANT TO FIX UGHHHG)\n",
    "  x_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "\n",
    "  # train the model\n",
    "  model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "  # evaluate the model\n",
    "  test_loss, test_Acc = model.evaluate(x_test, y_test)\n",
    "  print('Test accuracy:', test_Acc)\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "def model_save(model):\n",
    "  # save the model\n",
    "  model.save('saved_model/my_model')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging function\n",
    "def data_plot(df):\n",
    "    #debugging function. does not need to be called, or return anything\n",
    "\n",
    "    # plot the first 100 column 'AccelerationX' and 'AccelerationX_fft'\n",
    "    df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].iloc[:100].plot()\n",
    "\n",
    "    # Versus Head (the same)\n",
    "    #df[['AccelerationX_fft', 'AccelerationY_fft', 'AccelerationZ_fft']].head(100).plot()\n",
    "    df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].head(100).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919ada50126e9b7679f5f5dbe18aa91f971b460080d3011effa906ebff41bb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
