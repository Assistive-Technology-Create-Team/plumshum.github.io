{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Assistive-Technology-Create-Team/plumshum.github.io/blob/new_data_acquisition_and_machine_learning/modified_machine_learning_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use this [FallALlID2.csv file](https://drive.google.com/file/d/1Oi4Y_-EtZxU9mOAn-v5a93EDW43gpS1n/view?usp=sharing). Make sure to upload your own version to your Google Drive. \n",
        "\n",
        "1. Install Packages\n",
        "2. Mount Drive\n",
        "3. Change Google Colab Runtime to use GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8fMTFViRlwm"
      },
      "source": [
        "4. Run All the remaining cells until the 2nd to last one. This cell will run all the other functions\n",
        "```\n",
        "run_all()\n",
        "```\n",
        "5. The 3rd to last cell has a line\n",
        "\n",
        "```\n",
        "var = 0\n",
        "x_train, x_test, y_train, y_test = data_split(df, var)\n",
        "...\n",
        "model = train_and_accurary_model(model, x_train, x_test, y_train, y_test, var)\n",
        "\n",
        "```\n",
        "Every time you execute `run_all()`, change the variable `var` by 1 until 6. `var` represent a different amount of features used. \n",
        "\n",
        "6. Every time a model is saved, it should be saved in your Google Drive, and you can manually save it to your local machine. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfImyuhHOOiU"
      },
      "outputs": [],
      "source": [
        "#Run to install packages. Will take a few minutes\n",
        "%pip install numpy\n",
        "%pip install pandas\n",
        "%pip install os-sys\n",
        "%pip install matplotlib\n",
        "%pip install seaborn\n",
        "%pip install scikit-learn\n",
        "%pip install \"tensorflow-gpu<2.10\"\n",
        "%pip install \"tensorflow<2.10\"\n",
        "%pip install \"keras<2.10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoZIOzMROOiV",
        "outputId": "882e7e08-f2b4-4b1b-ed5c-7c5c051f10db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# If you are on Google Colab run this\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFTtpuwdOOiW",
        "outputId": "07f2173f-ca4a-4ddf-9254-708d2be10bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn \n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, KLDivergence\n",
        "import sklearn.model_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#If you do not see 1 Physical GPUs, 1 Logical GPUs, then you are most likely not using a GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CYuuRh9IOOiW"
      },
      "outputs": [],
      "source": [
        "def data_collection():\n",
        "\n",
        "    # import csv file\n",
        "    # ON GOOGLE COLAB\n",
        "        # read csv file from your google drive. find the file in your drive and copy the path and replace\n",
        "        # the path in the read_csv function with the path to your file\n",
        "    df = pd.read_csv('FallAllD2.csv')\n",
        "    # convert all columns to float32\n",
        "    df = df.astype('float32')\n",
        "    print(\"finished collecting data\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fKM-0yEYOOiX"
      },
      "outputs": [],
      "source": [
        "def data_label(df):\n",
        "    # add a new column called \"IsFall\" that is 1 if the ActivityID > 100, and 0 if it is not\n",
        "    df['IsFall'] = df['ActivityID'].apply(lambda x: 1 if x > 100 else 0)\n",
        "    return df\n",
        "\n",
        "def data_split(df, num):\n",
        "    df = data_label(df)\n",
        "    x = df[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "    # split the data into features and labels\n",
        "    if num == 0: x = df[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "    elif num == 1: x = df[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z']]\n",
        "    elif num == 2: x = df[['Device','Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "    elif num == 3: x = df[['Device','Acc_x','Acc_y','Acc_z', 'Bar_x', 'Bar_y']]\n",
        "    elif num == 4: x = df[['Device','Acc_x','Acc_y','Acc_z']]\n",
        "    elif num == 5: x = df[['Device','Gyr_x', 'Gyr_y', 'Gyr_z']]\n",
        "    elif num == 6: x = df[['Device','Bar_x', 'Bar_y']]\n",
        "    y = df['IsFall']\n",
        "\n",
        "    #print(\"x is:\", x)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    x = scaler.fit_transform(x)\n",
        "    x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
        "    \n",
        "    #Spliting Data\n",
        "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.2)\n",
        "    print('x y shape: ', x_train.shape, y_train.shape)\n",
        "\n",
        "    print(\"data split\")\n",
        "\n",
        "    return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GTyAtgZ0OOiY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def model_create(x_train, layer1_input = 512, layer2_input = 128):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(layer1_input, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "  model.add(Dropout(0.2))\n",
        "  \n",
        "  # add a Flatten layer using x_train as input shape\n",
        "  #model.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "\n",
        "  model.add(Dense(layer2_input, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  # for activity classification, we need 136 neurons in the output layer and categorical crossentropy as the loss function\n",
        "  #model.add(Dense(136, activation='softmax'))\n",
        "  #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  # for IsFall classification, we need 1 neuron in the output layer and binary crossentropy as the loss function\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def train_and_accurary_model(model, x_train, x_test, y_train, y_test, num):\n",
        "\n",
        "  # train the model\n",
        "  model.fit(x_train, y_train, epochs=2, batch_size=256, validation_split=0.1)\n",
        "\n",
        "  # evaluate the model\n",
        "  test_loss, test_Acc = model.evaluate(x_test, y_test)\n",
        "  print('Test accuracy:', test_Acc)\n",
        "  model.summary()\n",
        "  print(\"Confusion Matrix\")\n",
        "  y_pred = model.predict(x_test)\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  confusion_mtx = confusion_matrix(y_test, y_pred)\n",
        "  confusion_mtx_percent = confusion_mtx / confusion_mtx.sum(axis=1)[:, np.newaxis]\n",
        "  print(confusion_mtx_percent)\n",
        "\n",
        "  # Save Model to Local Machine\n",
        "  file_name = 'model' + str(num) + '_device2_aggregate.h5'\n",
        "\n",
        "  model.save(file_name)\n",
        "  #from google.colab import files\n",
        "  #files.download(file_name)  # Download to local machine\n",
        "  print(\"Model downloaded to local machine\")\n",
        "\n",
        "  # Save Model to Google Drive\n",
        "  #model.save('/content/drive/My Drive/' + file_name )\n",
        "  #print(\"ModelÂ saved to Google Drive\")\n",
        "  \n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vAWvhOnZOOiX"
      },
      "outputs": [],
      "source": [
        "def run_all():\n",
        "    df = data_collection()\n",
        "    df = df[df['Device'] == 2]\n",
        "    # 1: Neck, 2: Wrist, 3: Waist\n",
        "    \n",
        "    var = 0 #change this number from 0 - 6\n",
        "    x_train, x_test, y_train, y_test = data_split(df, var) \n",
        "    print(x_train.shape, y_train.shape)\n",
        "    print(x_test.shape, y_test.shape)\n",
        "\n",
        "    # Create and Train Model\n",
        "    model = model_create(x_train)\n",
        "    print(\"Model Created\")\n",
        "    model = train_and_accurary_model(model, x_train, x_test, y_train, y_test, var)\n",
        "    print(\"Model Trained\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "finished collecting data\n"
          ]
        }
      ],
      "source": [
        "df = data_collection()\n",
        "original_df = df.copy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get rid of nAn values from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "989.34985 1029.7147\n"
          ]
        }
      ],
      "source": [
        "df = original_df.copy()\n",
        "\n",
        "# find the range of Bar_x\n",
        "print(df['Bar_x'].min(), df['Bar_x'].max())\n",
        "# drop all rows where Bar_x is 'nan'\n",
        "df = df[df['Bar_x'].notna()]\n",
        "# keep a copy of df\n",
        "df_copy = df.copy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Only consider data from Wrist Device. \n",
        "Split Data\n",
        "Create the Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df_copy.copy()\n",
        "# 1: Neck, 2: Wrist, 3: Waist\n",
        "df = df[df['Device'] == 2]\n",
        "\n",
        "var = 0 #change this number from 0 - 6\n",
        "x_train, x_test, y_train, y_test = data_split(df, var) \n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "# Create and Train Model\n",
        "teacher_model = model_create(x_train)\n",
        "print(\"Model Created\")\n",
        "teacher_model = train_and_accurary_model(teacher_model, x_train, x_test, y_train, y_test, var)\n",
        "print(\"Model Trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate the model\n",
        "print(\"Confusion Matrix\")\n",
        "y_pred = teacher_model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "confusion_mtx = confusion_matrix(y_test, y_pred)\n",
        "confusion_mtx_percent = confusion_mtx / confusion_mtx.sum(axis=1)[:, np.newaxis]\n",
        "#print(confusion_mtx_percent)\n",
        "\n",
        "# Save Model to Local Machine\n",
        "file_name = 'teacher_model' + str(var) + '_device2_aggregate.h5'\n",
        "\n",
        "teacher_model.save(file_name)\n",
        "#from google.colab import files\n",
        "#files.download(file_name)  # Download to local machine\n",
        "print(\"Model downloaded to local machine\")\n",
        "\n",
        "print(\"Teacher Model Trained\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are creating the Student Models using Knowledge Distillation.\n",
        "Get a copy of the dataset. Only include data from 'Wrist' device. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_acc= df_copy.copy()\n",
        "# only get Acc_x, Acc_y, Acc_z \n",
        "df_acc = df_acc[df_acc['Device'] == 2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of creating a loss function, we use the predictions from the teacher mdoel. This is part of a method called solf labeling. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15719/15719 [==============================] - 18s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "df_acc= df_copy.copy()\n",
        "# only get Acc_x, Acc_y, Acc_z \n",
        "df_acc = df_acc[df_acc['Device'] == 2]\n",
        "x = df_acc[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "df_acc = data_label(df_acc)\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
        "teacher_predictions = teacher_model.predict(x)\n",
        "# round predictions\n",
        "teacher_predictions = np.round(teacher_predictions).astype(int)\n",
        "df_acc['Teacher_Predictions'] = teacher_predictions\n",
        "df_acc_copy = df_acc.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>SubjectID</th>\n",
              "      <th>Device</th>\n",
              "      <th>ActivityID</th>\n",
              "      <th>TrialNo</th>\n",
              "      <th>Acc_x</th>\n",
              "      <th>Acc_y</th>\n",
              "      <th>Acc_z</th>\n",
              "      <th>Gyr_x</th>\n",
              "      <th>Gyr_y</th>\n",
              "      <th>Gyr_z</th>\n",
              "      <th>Bar_x</th>\n",
              "      <th>Bar_y</th>\n",
              "      <th>IsFall</th>\n",
              "      <th>Teacher_Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>880600</th>\n",
              "      <td>880600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2588.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>-569.0</td>\n",
              "      <td>-178.0</td>\n",
              "      <td>-18.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>1020.811157</td>\n",
              "      <td>30.001707</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880601</th>\n",
              "      <td>880601.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2584.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>-586.0</td>\n",
              "      <td>-164.0</td>\n",
              "      <td>-14.0</td>\n",
              "      <td>562.0</td>\n",
              "      <td>1020.830872</td>\n",
              "      <td>30.000162</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880602</th>\n",
              "      <td>880602.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2570.0</td>\n",
              "      <td>1147.0</td>\n",
              "      <td>-593.0</td>\n",
              "      <td>-148.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>1020.859192</td>\n",
              "      <td>30.002243</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880603</th>\n",
              "      <td>880603.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2585.0</td>\n",
              "      <td>1155.0</td>\n",
              "      <td>-592.0</td>\n",
              "      <td>-123.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>1020.826782</td>\n",
              "      <td>30.000498</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880604</th>\n",
              "      <td>880604.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2584.0</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>-598.0</td>\n",
              "      <td>-103.0</td>\n",
              "      <td>-9.0</td>\n",
              "      <td>438.0</td>\n",
              "      <td>1020.810181</td>\n",
              "      <td>30.000162</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0.1  Unnamed: 0  SubjectID  Device  ActivityID  TrialNo  \\\n",
              "880600      880600.0         0.0        1.0     2.0       101.0      1.0   \n",
              "880601      880601.0         1.0        1.0     2.0       101.0      1.0   \n",
              "880602      880602.0         2.0        1.0     2.0       101.0      1.0   \n",
              "880603      880603.0         3.0        1.0     2.0       101.0      1.0   \n",
              "880604      880604.0         4.0        1.0     2.0       101.0      1.0   \n",
              "\n",
              "         Acc_x   Acc_y  Acc_z  Gyr_x  Gyr_y  Gyr_z        Bar_x      Bar_y  \\\n",
              "880600  2588.0  1129.0 -569.0 -178.0  -18.0  610.0  1020.811157  30.001707   \n",
              "880601  2584.0  1129.0 -586.0 -164.0  -14.0  562.0  1020.830872  30.000162   \n",
              "880602  2570.0  1147.0 -593.0 -148.0  -10.0  520.0  1020.859192  30.002243   \n",
              "880603  2585.0  1155.0 -592.0 -123.0  -12.0  480.0  1020.826782  30.000498   \n",
              "880604  2584.0  1140.0 -598.0 -103.0   -9.0  438.0  1020.810181  30.000162   \n",
              "\n",
              "        IsFall  Teacher_Predictions  \n",
              "880600       1                    1  \n",
              "880601       1                    1  \n",
              "880602       1                    1  \n",
              "880603       1                    1  \n",
              "880604       1                    1  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find 'IsFall' == 1 and print the first 5 rows\n",
        "df_acc[df_acc['IsFall'] == 1].head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`student_train_data` splits the dataset in x and y values. the 'num' tells us how to configure the sensors. \n",
        "\n",
        "`y_train` uses teacher's predictions column\n",
        "\n",
        "`y_test` uses isFall column. It's important for the student model to be optmized using real data, not the teacher's data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "def student_train_data(df, num):\n",
        "    df = data_label(df)\n",
        "    x = df[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "    if num == 1: \n",
        "        # drop 'Bar_x' and 'Bar_y' from x\n",
        "        x = x.drop(['Bar_x', 'Bar_y'], axis=1)\n",
        "\n",
        "    if num == 2: \n",
        "        # drop 'Acc_x', 'Acc_y', 'Acc_z' from x\n",
        "        x = x.drop(['Acc_x', 'Acc_y', 'Acc_z'], axis=1)\n",
        "\n",
        "    if num == 3:\n",
        "        # drop 'Gyr_x', 'Gyr_y', 'Gyr_z' from x\n",
        "        x = x.drop(['Gyr_x', 'Gyr_y', 'Gyr_z'], axis=1)\n",
        "    \n",
        "    if num == 4:\n",
        "        # drop 'Bar_x' and 'Bar_y' from x\n",
        "        x = x.drop(['Bar_x', 'Bar_y'], axis=1)\n",
        "        # drop 'Gyr_x', 'Gyr_y', 'Gyr_z' from x\n",
        "        x = x.drop(['Gyr_x', 'Gyr_y', 'Gyr_z'], axis=1)\n",
        "    \n",
        "    if num == 5:\n",
        "        # drop 'Bar_x' and 'Bar_y' from x\n",
        "        x = x.drop(['Bar_x', 'Bar_y'], axis=1)\n",
        "        # drop 'Acc_x', 'Acc_y', 'Acc_z' from x\n",
        "        x = x.drop(['Acc_x', 'Acc_y', 'Acc_z'], axis=1)\n",
        "\n",
        "    if num == 6:\n",
        "        # drop 'Gyr_x', 'Gyr_y', 'Gyr_z' from x\n",
        "        x = x.drop(['Gyr_x', 'Gyr_y', 'Gyr_z'], axis=1)\n",
        "        # drop 'Acc_x', 'Acc_y', 'Acc_z' from x\n",
        "        x = x.drop(['Acc_x', 'Acc_y', 'Acc_z'], axis=1)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    x = scaler.fit_transform(x)\n",
        "    x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
        "\n",
        "    # use 'IsFall' and 'Teacher_Predictions' as y\n",
        "    y = df[['IsFall', 'Teacher_Predictions']]\n",
        "    \n",
        "    #Spliting Data\n",
        "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.2) \n",
        "    # use 'Teacher_Predictions' as y_train and 'IsFall' as y_test\n",
        "    y_train = y_train['Teacher_Predictions']\n",
        "    y_test = y_test['IsFall']\n",
        "    return x_train, x_test, y_train, y_test\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split data for student model. \n",
        "Student Model is given same number of layers, half the number of neurons, and a configured number of sensors. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "var = 1\n",
        "df_acc = df_acc_copy.copy()\n",
        "student_x_train, student_x_test, student_y_train, student_y_test = student_train_data(df_acc, var) \n",
        "\n",
        "print (student_x_train.shape)\n",
        "print(x_train.shape)\n",
        "\n",
        "#print(student_x_train.shape, student_y_train.shape)\n",
        "#print(student_x_test.shape, student_y_test.shape)\n",
        "\n",
        "optimizer = Adam()\n",
        "loss_fn = 'binary_crossentropy'\n",
        "\n",
        "# Define the student model\n",
        "student_model = Sequential()\n",
        "student_model.add(LSTM(256, input_shape=(student_x_train.shape[1], student_x_train.shape[2])))\n",
        "student_model.add(Dropout(0.2))\n",
        "student_model.add(Dense(64, activation='relu'))\n",
        "student_model.add(Dropout(0.3))\n",
        "student_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "student_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the student model using soft labels\n",
        "student_model.fit(student_x_train, student_y_train, epochs=2, batch_size=256, validation_split=0.2)\n",
        "test_loss, test_Acc = student_model.evaluate(student_x_test, student_y_test)\n",
        "print('Test accuracy:', test_Acc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display Model Statistics and Saves Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# evaluate the model\n",
        "print(\"Confusion Matrix\")\n",
        "y_pred = student_model.predict(student_x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "confusion_mtx = confusion_matrix(student_y_test, y_pred)\n",
        "confusion_mtx_percent = confusion_mtx / confusion_mtx.sum(axis=1)[:, np.newaxis]\n",
        "#print(confusion_mtx_percent)\n",
        "\n",
        "# Save Model to Local Machine\n",
        "file_name = 'student_model' + str(var) + '_device2_aggregate.h5'\n",
        "\n",
        "student_model.save(file_name)\n",
        "#from google.colab import files\n",
        "#files.download(file_name)  # Download to local machine\n",
        "print(\"Model downloaded to local machine\")\n",
        "\n",
        "print(\"Student Model Trained\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS04lWctRwbb"
      },
      "source": [
        "Do not run the cell below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sensors are configured based on num. \n",
        "The dataset is split.\n",
        "This is all in prepartions for the creation of our student models using knowledge distillation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def student_data_split(df, num):\n",
        "    df = data_label(df)\n",
        "    x = df[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "    if num == 1: \n",
        "        # set 'Bar_x' and 'Bar_y' to 0\n",
        "        df['Bar_x'] = 0\n",
        "        df['Bar_y'] = 0\n",
        "\n",
        "    if num == 2: \n",
        "        # set 'Acc_x', 'Acc_y', 'Acc_z' to 0\n",
        "        df['Acc_x'] = 0\n",
        "        df['Acc_y'] = 0\n",
        "        df['Acc_z'] = 0\n",
        "\n",
        "    if num == 3:\n",
        "        # set 'Gyr_x', 'Gyr_y', 'Gyr_z' to 0\n",
        "        df['Gyr_x'] = 0\n",
        "        df['Gyr_y'] = 0\n",
        "        df['Gyr_z'] = 0\n",
        "    \n",
        "    if num == 4:\n",
        "        # set 'Bar_x' and 'Bar_y' to 0\n",
        "        df['Bar_x'] = 0\n",
        "        df['Bar_y'] = 0\n",
        "        # set 'Gyr_x', 'Gyr_y', 'Gyr_z' to 0\n",
        "        df['Gyr_x'] = 0\n",
        "        df['Gyr_y'] = 0\n",
        "        df['Gyr_z'] = 0\n",
        "    \n",
        "    if num == 5:\n",
        "        # set 'Bar_x' and 'Bar_y' to 0\n",
        "        df['Bar_x'] = 0\n",
        "        df['Bar_y'] = 0\n",
        "        # set 'Acc_x', 'Acc_y', 'Acc_z' to 0\n",
        "        df['Acc_x'] = 0\n",
        "        df['Acc_y'] = 0\n",
        "        df['Acc_z'] = 0\n",
        "\n",
        "    if num == 6:\n",
        "        # set 'Gyr_x', 'Gyr_y', 'Gyr_z' to 0\n",
        "        df['Gyr_x'] = 0\n",
        "        df['Gyr_y'] = 0\n",
        "        df['Gyr_z'] = 0\n",
        "        # set 'Acc_x', 'Acc_y', 'Acc_z' to 0\n",
        "        df['Acc_x'] = 0\n",
        "        df['Acc_y'] = 0\n",
        "        df['Acc_z'] = 0\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    x = scaler.fit_transform(x)\n",
        "    x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
        "\n",
        "    # convert df to float32\n",
        "    df = df.astype('float32')\n",
        "\n",
        "    y = df['IsFall']\n",
        "    \n",
        "    #Spliting Data\n",
        "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.2)    \n",
        "    return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Old Method by creating an actual loss function using the teacher model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "var = 6\n",
        "student_x_train, student_x_test, student_y_train, student_y_test = student_data_split(df_acc, var) \n",
        "print(student_x_train.shape, student_y_train.shape)\n",
        "print(student_x_test.shape, student_y_test.shape)\n",
        "\n",
        "\n",
        "# Knowledge distillation\n",
        "temperature = 5.0\n",
        "teacher_logits = tf.keras.layers.Lambda(lambda x: x / temperature)(teacher_model.layers[-2].output)\n",
        "teacher_model_logits = tf.keras.models.Model(teacher_model.inputs, teacher_logits)\n",
        "\n",
        "# Function to create a knowledge distillation loss\n",
        "def knowledge_distillation_loss(y_true, y_pred_logits):\n",
        "    y_pred = tf.nn.sigmoid(y_pred_logits / temperature)\n",
        "    y_true = tf.nn.sigmoid(y_true / temperature)\n",
        "    return KLDivergence()(y_true, y_pred)\n",
        "\n",
        "# Custom loss function that combines knowledge distillation loss and the original binary crossentropy loss\n",
        "def combined_loss(y_true, y_pred):\n",
        "    kd_loss = knowledge_distillation_loss(y_true, y_pred)\n",
        "    original_loss = BinaryCrossentropy(from_logits=True)(y_true, y_pred)\n",
        "    return kd_loss + original_loss\n",
        "\n",
        "student_model = Sequential()\n",
        "student_model.add(LSTM(256, input_shape=(student_x_train.shape[1], student_x_train.shape[2])))\n",
        "student_model.add(Dropout(0.2))\n",
        "student_model.add(Dense(64, activation='relu'))\n",
        "student_model.add(Dropout(0.3))\n",
        "student_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "student_model.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])\n",
        "\n",
        "student_model.fit(student_x_train, student_y_train, epochs=2, batch_size=256, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ApXk4OasOOiY"
      },
      "outputs": [],
      "source": [
        "# CODE DOESN'T WORK YET\n",
        "# Get model from folder all_models. take model summaries and put them into a txt file. download txt file to local machine\n",
        "def get_model_summaries():\n",
        "    import os\n",
        "    from keras.models import load_model\n",
        "    from keras.utils.vis_utils import plot_model\n",
        "    from keras.utils import print_summary\n",
        "    \n",
        "    # get all files in the folder\n",
        "    files = os.listdir('all models')\n",
        "    print(files)\n",
        "    \n",
        "    # open a file to write the model summaries to\n",
        "    f = open(\"model_summaries.txt\", \"w\")\n",
        "    \n",
        "    # loop through all files in the folder\n",
        "    for file in files:\n",
        "        # load the model\n",
        "        model = load_model('all_models/' + file)\n",
        "        # get the model summary\n",
        "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "        # get the model plot\n",
        "        plot_model(model, to_file='model_plots/' + file + '.png', show_shapes=True, show_layer_names=True)\n",
        "        # write a line break\n",
        "        f.write('\\n\\n')\n",
        "    f.close()\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "919ada50126e9b7679f5f5dbe18aa91f971b460080d3011effa906ebff41bb2e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
