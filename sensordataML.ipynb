{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model\n",
    "1. Make sure all packages are installed (WINDOWS)\n",
    "\n",
    "*    pip install numpy\n",
    "*   pip install pandas\n",
    "*   pip install os-sys\n",
    "*    pip install matplotlib\n",
    "*   pip install seaborn\n",
    "*   pip install scikit-learn\n",
    "*   pip install keras\n",
    "*   pip install tensorflow \n",
    "\n",
    "1. Make sure all packages are installed (MACS AND/OR ANACONDA ENVIRONMENT)\n",
    "*   conda  install numpy\n",
    "*   conda  install pandas\n",
    "*   conda  install os-sys\n",
    "*   conda  install matplotlib\n",
    "*   conda  install seaborn\n",
    "*   conda  install scikit-learn\n",
    "*   conda  install keras\n",
    "*   conda  install tensorflow "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Issues:\n",
    " * can I reshape before putting in LSTM layer :(\n",
    " * would y.to_categorical be better? \n",
    "\n",
    "Todo:\n",
    "* test script and sensordata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN IF YOU ARE NOT USING WINDOWS AND/OR NOT USING ANACONDA\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install os-sys\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install keras\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import sklearn.model_selection\n",
    "\n",
    "#Yeah... that's all\n",
    "run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/harnoor343/fall-detection-accelerometer-data\n",
    "#Link to chen hua min's code: https://www.kaggle.com/code/mmttdebbcc/notebook9689a93a64  \n",
    "\n",
    "def data_collection():\n",
    "    # create a new directory called 'kaggle_normalized', ignore it if it already exists\n",
    "    os.makedirs('./normalized', exist_ok=True)\n",
    "\n",
    "    labels = ['runfall', 'downSit', 'freeFall', 'runSit', 'walkFall', 'walkSit']\n",
    "    for label in labels:\n",
    "        #read all csv files in the directory \"archive' + label, delimit by ';'\n",
    "        files = glob.glob('./archive/' + label + '/*.csv')\n",
    "        df = pd.concat([pd.read_csv(f, sep=';') for f in files], ignore_index=True)\n",
    "        # assign label to df column 'Label'\n",
    "        df['Label'] = label\n",
    "        # save columns 'DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label' to a new csv file\n",
    "        df[['DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label']].to_csv('./normalized/' + label + '.csv', index=False)\n",
    "        \n",
    "        \n",
    "    df = pd.concat([pd.read_csv(f) for f in glob.glob('./normalized/*.csv')], ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_normalize(df):\n",
    "    # for each column in 'Accerlation', 'AccelerationY', 'AccelerationZ',\n",
    "    # add a new column that is the fft of the original column\n",
    "    for c in ['AccelerationX', 'AccelerationY', 'AccelerationZ']:\n",
    "        df[c + '_fft'] = np.fft.fft(df[c])\n",
    "\n",
    "    # debug purposes\n",
    "    for c in df.columns:\n",
    "        print(c)\n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_plot(df):\n",
    "    #debugging function. does not need to be called, or return anything\n",
    "\n",
    "    # plot the first 100 column 'AccelerationX' and 'AccelerationX_fft'\n",
    "    df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].iloc[:100].plot()\n",
    "\n",
    "    # Versus Head (the same)\n",
    "    #df[['AccelerationX_fft', 'AccelerationY_fft', 'AccelerationZ_fft']].head(100).plot()\n",
    "    df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].head(100).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_categorical(df):\n",
    "    # convert categorical data to numerical data\n",
    "    # TODO: change to y.categorical_data \n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    df['Label'] = df['Label'].cat.codes\n",
    "    print(df['Label'].unique())\n",
    "\n",
    "    # convert column `DeviceOrientation` to numerical data\n",
    "    df['DeviceOrientation'] = df['DeviceOrientation'].astype('category')\n",
    "    df['DeviceOrientation'] = df['DeviceOrientation'].cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df):\n",
    "    x = np.array(df.drop(['Label'], 1)) #drops row 'Label'\n",
    "    y = np.array(df[\"Label\"])\n",
    "\n",
    "    #Spliting Data\n",
    "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.3)\n",
    "\n",
    "    # reshape training and testing data\n",
    "    y_train = np.array(y_train).reshape(-1,1) # (-1,1) because our data has a single feature, and a 'n' amount of rows\n",
    "    y_test = np.array(y_test).reshape(-1,1) # (-1,1) bec  ause our data has a single feature, and a 'n' amount of rows\n",
    "    x_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(x_train):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128, input_shape=(x_train.shape[1], 1)))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(6, activation='softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_accurary_model(model, x_train, x_test, y_train, y_test):\n",
    "  # train the model\n",
    "  #reshape the features for the LSTM layer (I REALLY WANT TO FIX UGHHHG)\n",
    "  x_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "  model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "  test_loss, test_Acc = model.evaluate(x_test, y_test)\n",
    "  print('Test accuracy:', test_Acc)\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(model):\n",
    "  # save the model\n",
    "  model.save('saved_model/my_model')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    df = data_collection()\n",
    "    df = data_normalize(df)\n",
    "    df = data_categorical(df)\n",
    "    x_train, x_test, y_train, y_test = data_split(df)\n",
    "    #print the size of the training and testing data\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "    model = model_create(x_train)\n",
    "    model = train_and_accurary_model(model, x_train, x_test, y_train, y_test)\n",
    "    model_save(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LTSM version\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import sklearn.model_selection\n",
    "\n",
    "# can you drop accx, accy, and accz?\n",
    "x = np.array(df.drop(['Label'], 1)) #drops row 'Label'\n",
    "y = np.array(df[\"Label\"])\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.3)\n",
    "y_train = np.array(y_train).reshape(-1,1) # (-1,1) because our data has a single feature, and a 'n' amount of rows\n",
    "\n",
    "#build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#reshape the features for the LSTM layer\n",
    "x_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "\n",
    "#reshape the testing data\n",
    "y_test = np.array(y_test).reshape(-1,1) # (-1,1) bec  ause our data has a single feature, and a 'n' amount of rows\n",
    "x_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "#train the model\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=64, verbose=1, validation_split = 0.2)\n",
    "\n",
    "test_loss, test_Acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_Acc)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a path for the saved model to the current directory\n",
    "os.makedirs('./saved_model', exist_ok=True)\n",
    "model.save('./saved_model/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Old Version \n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# build a neural network that uses the fft of the accelerometer data to predict the label\n",
    "model = Sequential()\n",
    "#flatten the input to a 1D array\n",
    "model.add(Dense(64, activation='relu', input_shape=(x.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=20, batch_size= 20, validation_split=0.2)\n",
    "#evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "#print model summary\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919ada50126e9b7679f5f5dbe18aa91f971b460080d3011effa906ebff41bb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
