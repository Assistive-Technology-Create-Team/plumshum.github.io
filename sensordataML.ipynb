{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure all packages are installed\n",
    "\n",
    "*    pip install numpy\n",
    "*   pip install pandas\n",
    "*   pip install os-sys\n",
    "*    pip install matplotlib\n",
    "*   pip install seaborn\n",
    "*   pip install scikit-learn\n",
    "*   pip install keras\n",
    "*   pip install tensorflow*\n",
    "\n",
    "2. Collected Data from sensor py to this file "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Issues:\n",
    " * Should AccelerationX, Y, Z still be kept in dataframe?\n",
    "    inputshape is 7, not 5 \n",
    " * not sure why we have to reshape features twice \n",
    " * need cat.codes and Label_Encoder, or just one?\n",
    " * would y.to_categorical be better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/harnoor343/fall-detection-accelerometer-data\n",
    "#Link to chen hua min's code: https://www.kaggle.com/code/mmttdebbcc/notebook9689a93a64  \n",
    "# create a new directory called 'kaggle_normalized', ignore it if it already exists\n",
    "os.makedirs('./normalized', exist_ok=True)\n",
    "\n",
    "labels = ['runfall', 'downSit', 'freeFall', 'runSit', 'walkFall', 'walkSit']\n",
    "for label in labels:\n",
    "    #read all csv files in the director \"./kaggle_data/\" + l, delimit by ';'\n",
    "    #this is different from chen human min project\n",
    "    files = glob.glob('./archive/' + label + '/*.csv')\n",
    "    #assign l to to df column 'Label'\n",
    "    df = pd.concat([pd.read_csv(f, sep=';') for f in files], ignore_index=True)\n",
    "    # assign l to df column 'Label'\n",
    "    df['Label'] = label\n",
    "    # save columns 'DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label' to a new csv file\n",
    "    df[['DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label']].to_csv('./normalized/' + label + '.csv', index=False)\n",
    "\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('./normalized/*.csv')], ignore_index = True)\n",
    "columns = ['DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for each column in 'Accerlation', 'AccelerationY', 'AccelerationZ', and a new column that is the fft of the original column\n",
    "for c in ['AccelerationX', 'AccelerationY', 'AccelerationZ']:\n",
    "    df[c + '_fft'] = np.fft.fft(df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 100 column 'AccelerationX' and 'AccelerationX_fft'\n",
    "df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].iloc[:100].plot()\n",
    "\n",
    "# Versus Head (the same)\n",
    "#df[['AccelerationX_fft', 'AccelerationY_fft', 'AccelerationZ_fft']].head(100).plot()\n",
    "df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].head(100).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging Code (Mardown Text)\n",
    "\n",
    " print the shape of the dataframe\n",
    "\n",
    "              print(df.shape) \n",
    "\n",
    " print each column's name in the dataframe\n",
    " \n",
    "              print(df.columns)\n",
    "\n",
    "(202599, 8)\n",
    "Index(['DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ',\n",
    "       'Label', 'AccelerationX_fft', 'AccelerationY_fft', 'AccelerationZ_fft'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to numerical data\n",
    "df['Label'] = df['Label'].astype('category')\n",
    "df['Label'] = df['Label'].cat.codes\n",
    "# df.head()\n",
    "\n",
    "# convert column `DeviceOrientation` to numerical data\n",
    "df['DeviceOrientation'] = df['DeviceOrientation'].astype('category')\n",
    "df['DeviceOrientation'] = df['DeviceOrientation'].cat.codes\n",
    "df.head()\n",
    "\n",
    "x = np.array(df.drop(['Label'], 1)) #drops row 'Label'\n",
    "y = np.array(df[\"Label\"])\n",
    "\n",
    "import sklearn.model_selection\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LTSM version\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode the target. \n",
    "encoder = LabelEncoder()\n",
    "    #LabelEncoder encodes Encode target labels with value between 0 and n_classes-1.\n",
    "    # This transformer should be used to encode target values, *i.e.* y, and not the input X\n",
    "encoder.fit(y_train)\n",
    "target = encoder.transform(y_train) #tranform to normalised encoding \n",
    "target = np.array(target).reshape(-1,1) # (-1,1) because our data has a single feature, and a 'n' amount of rows\n",
    "print(target)\n",
    "\n",
    "#build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#reshape the features for the LSTM layer\n",
    "# don't completely understand this part\n",
    "features = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "#x_train.shape:  141819  x_train.shape[1]:  7  1:  1\n",
    "\n",
    "#train the model\n",
    "model.fit(features, target, epochs=1, batch_size=20, verbose=1, validation_split = 0.2)\n",
    "\n",
    "test_loss, test_Acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_Acc)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 1.3953 - accuracy: 0.4176 - val_loss: 1.2223 - val_accuracy: 0.4945\n",
      "Epoch 2/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 1.1681 - accuracy: 0.5228 - val_loss: 1.1299 - val_accuracy: 0.5494\n",
      "Epoch 3/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 1.0708 - accuracy: 0.5782 - val_loss: 0.9613 - val_accuracy: 0.6229\n",
      "Epoch 4/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.9598 - accuracy: 0.6251 - val_loss: 0.9130 - val_accuracy: 0.6418\n",
      "Epoch 5/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.9144 - accuracy: 0.6412 - val_loss: 0.8825 - val_accuracy: 0.6490\n",
      "Epoch 6/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.8830 - accuracy: 0.6513 - val_loss: 0.8564 - val_accuracy: 0.6580\n",
      "Epoch 7/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.8622 - accuracy: 0.6594 - val_loss: 0.8439 - val_accuracy: 0.6618\n",
      "Epoch 8/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.8453 - accuracy: 0.6651 - val_loss: 0.8443 - val_accuracy: 0.6642\n",
      "Epoch 9/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.8351 - accuracy: 0.6702 - val_loss: 0.8232 - val_accuracy: 0.6731\n",
      "Epoch 10/25\n",
      "5673/5673 [==============================] - 9s 2ms/step - loss: 0.8174 - accuracy: 0.6769 - val_loss: 0.7978 - val_accuracy: 0.6828\n",
      "Epoch 11/25\n",
      "5673/5673 [==============================] - 9s 2ms/step - loss: 0.8053 - accuracy: 0.6797 - val_loss: 0.7915 - val_accuracy: 0.6840\n",
      "Epoch 12/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7924 - accuracy: 0.6844 - val_loss: 0.7732 - val_accuracy: 0.6908\n",
      "Epoch 13/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7849 - accuracy: 0.6885 - val_loss: 0.7874 - val_accuracy: 0.6862\n",
      "Epoch 14/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7735 - accuracy: 0.6923 - val_loss: 0.7950 - val_accuracy: 0.6805\n",
      "Epoch 15/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7660 - accuracy: 0.6948 - val_loss: 0.7497 - val_accuracy: 0.7000\n",
      "Epoch 16/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7615 - accuracy: 0.6960 - val_loss: 0.8091 - val_accuracy: 0.6724\n",
      "Epoch 17/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7568 - accuracy: 0.6985 - val_loss: 0.7413 - val_accuracy: 0.7036\n",
      "Epoch 18/25\n",
      "5673/5673 [==============================] - 9s 2ms/step - loss: 0.7657 - accuracy: 0.6951 - val_loss: 0.7407 - val_accuracy: 0.7037\n",
      "Epoch 19/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7510 - accuracy: 0.7000 - val_loss: 0.7573 - val_accuracy: 0.6974\n",
      "Epoch 20/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7505 - accuracy: 0.7006 - val_loss: 0.7618 - val_accuracy: 0.6980\n",
      "Epoch 21/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7442 - accuracy: 0.7038 - val_loss: 0.7466 - val_accuracy: 0.6961\n",
      "Epoch 22/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7438 - accuracy: 0.7033 - val_loss: 0.7528 - val_accuracy: 0.7006\n",
      "Epoch 23/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7381 - accuracy: 0.7059 - val_loss: 0.7198 - val_accuracy: 0.7108\n",
      "Epoch 24/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7347 - accuracy: 0.7064 - val_loss: 0.7559 - val_accuracy: 0.6960\n",
      "Epoch 25/25\n",
      "5673/5673 [==============================] - 8s 1ms/step - loss: 0.7333 - accuracy: 0.7074 - val_loss: 0.7229 - val_accuracy: 0.7092\n",
      "1900/1900 [==============================] - 2s 1ms/step - loss: 0.7335 - accuracy: 0.7074\n",
      "Test accuracy: 0.7074037790298462\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 64)                512       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,542\n",
      "Trainable params: 17,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# build a neural network that uses the fft of the accelerometer data to predict the label\n",
    "model = Sequential()\n",
    "#flatten the input to a 1D array\n",
    "model.add(Dense(64, activation='relu', input_shape=(x.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=20, batch_size= 20, validation_split=0.2)\n",
    "#evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "#print model summary\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.6795163154602051 \n",
    "batch_Size = 24 epochs = 15\n",
    "batch_Size = 20, epochs = 20, two new Relu layers\n",
    "validation_split = 0.1\n",
    "epochs = 25, batch_Size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "print(x_train)\n",
    "# build a neural network that uses the fft of the accelerometer data to predict the label\n",
    "model = Sequential()\n",
    "# flatten the input data to a 1D array\n",
    "model.add(keras.layers.Flatten(input_shape=(12,)))\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(6,)))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919ada50126e9b7679f5f5dbe18aa91f971b460080d3011effa906ebff41bb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
