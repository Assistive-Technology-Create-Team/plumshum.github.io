{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Model\n",
    "good mroning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure all packages are installed (WINDOWS)\n",
    "\n",
    "*    pip install numpy\n",
    "*   pip install pandas\n",
    "*   pip install os-sys\n",
    "*    pip install matplotlib\n",
    "*   pip install seaborn\n",
    "*   pip install scikit-learn\n",
    "*   pip install keras\n",
    "*   pip install tensorflow "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure all packages are installed (MACS OR ANACONDA ENVIRONMENT)\n",
    "*   conda  install numpy\n",
    "*   conda  install pandas\n",
    "*   conda  install os-sys\n",
    "*   conda  install matplotlib\n",
    "*   conda  install seaborn\n",
    "*   conda  install scikit-learn\n",
    "*   conda  install keras\n",
    "*   conda  install tensorflow "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Issues:\n",
    " * not sure why we have to reshape features twice \n",
    " * would y.to_categorical be better? \n",
    "\n",
    "Todo:\n",
    "* create an model experimentation file\n",
    "* create the code for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN IF YOU ARE NOT USING WINDOWS AND/OR NOT USING ANACONDA\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install os-sys\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install keras\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeviceOrientation\n",
      "AccelerationX\n",
      "AccelerationY\n",
      "AccelerationZ\n",
      "Label\n",
      "AccelerationX_fft\n",
      "AccelerationY_fft\n",
      "AccelerationZ_fft\n",
      "[0 1 3 2 4 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyuz\\AppData\\Local\\Temp\\ipykernel_5892\\3664925110.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x = np.array(df.drop(['Label'], 1)) #drops row 'Label'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "model_create() missing 1 required positional argument: 'x_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run()\n",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m, in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[39m=\u001b[39m data_categorical(df)\n\u001b[0;32m      5\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m data_split(df)\n\u001b[1;32m----> 6\u001b[0m model \u001b[39m=\u001b[39m model_create()\n\u001b[0;32m      7\u001b[0m model \u001b[39m=\u001b[39m train_and_accurary_model(model, x_train, y_train, x_test, y_test)\n\u001b[0;32m      8\u001b[0m model_save(model)\n",
      "\u001b[1;31mTypeError\u001b[0m: model_create() missing 1 required positional argument: 'x_train'"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/harnoor343/fall-detection-accelerometer-data\n",
    "#Link to chen hua min's code: https://www.kaggle.com/code/mmttdebbcc/notebook9689a93a64  \n",
    "\n",
    "def data_collection():\n",
    "    # create a new directory called 'kaggle_normalized', ignore it if it already exists\n",
    "    os.makedirs('./normalized', exist_ok=True)\n",
    "\n",
    "    labels = ['runfall', 'downSit', 'freeFall', 'runSit', 'walkFall', 'walkSit']\n",
    "    for label in labels:\n",
    "        #read all csv files in the directory \"archive' + label, delimit by ';'\n",
    "        files = glob.glob('./archive/' + label + '/*.csv')\n",
    "        df = pd.concat([pd.read_csv(f, sep=';') for f in files], ignore_index=True)\n",
    "        # assign label to df column 'Label'\n",
    "        df['Label'] = label\n",
    "        # save columns 'DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label' to a new csv file\n",
    "        df[['DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label']].to_csv('./normalized/' + label + '.csv', index=False)\n",
    "        \n",
    "        \n",
    "    df = pd.concat([pd.read_csv(f) for f in glob.glob('./normalized/*.csv')], ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_normalize(df):\n",
    "    # for each column in 'Accerlation', 'AccelerationY', 'AccelerationZ',\n",
    "    # add a new column that is the fft of the original column\n",
    "    for c in ['AccelerationX', 'AccelerationY', 'AccelerationZ']:\n",
    "        df[c + '_fft'] = np.fft.fft(df[c])\n",
    "\n",
    "    # debug purposes\n",
    "    for c in df.columns:\n",
    "        print(c)\n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_plot(df):\n",
    "    #debugging function. does not need to be called, or return anything\n",
    "\n",
    "    # plot the first 100 column 'AccelerationX' and 'AccelerationX_fft'\n",
    "    df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].iloc[:100].plot()\n",
    "\n",
    "    # Versus Head (the same)\n",
    "    #df[['AccelerationX_fft', 'AccelerationY_fft', 'AccelerationZ_fft']].head(100).plot()\n",
    "    df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].head(100).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_categorical(df):\n",
    "    # convert categorical data to numerical data\n",
    "    # TODO: change to y.categorical_data \n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    df['Label'] = df['Label'].cat.codes\n",
    "    print(df['Label'].unique())\n",
    "\n",
    "    # convert column `DeviceOrientation` to numerical data\n",
    "    df['DeviceOrientation'] = df['DeviceOrientation'].astype('category')\n",
    "    df['DeviceOrientation'] = df['DeviceOrientation'].cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df):\n",
    "    x = np.array(df.drop(['Label'], 1)) #drops row 'Label'\n",
    "    y = np.array(df[\"Label\"])\n",
    "\n",
    "    #TODO CONFIRM IF I CAN CHANGE X_TRAIN RESHAPED FOR EARLIER\n",
    "    #Spliting Data\n",
    "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.3)\n",
    "\n",
    "    # reshape training and testing data\n",
    "    y_train = np.array(y_train).reshape(-1,1) # (-1,1) because our data has a single feature, and a 'n' amount of rows\n",
    "    x_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1) #TODO: test you out\n",
    "    y_test = np.array(y_test).reshape(-1,1) # (-1,1) bec  ause our data has a single feature, and a 'n' amount of rows\n",
    "    x_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(x_train):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128, input_shape=(x_train.shape[1], 1)))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(6, activation='softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_accurary_model(model, x_train, x_test, y_train, y_test):\n",
    "  # train the model\n",
    "  model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "  test_loss, test_Acc = model.evaluate(x_test, y_test)\n",
    "  print('Test accuracy:', test_Acc)\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(model):\n",
    "  # save the model\n",
    "  model.save('saved_model/my_model')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    df = data_collection()\n",
    "    df = data_normalize(df)\n",
    "    df = data_categorical(df)\n",
    "    x_train, x_test, y_train, y_test = data_split(df)\n",
    "    model = model_create(x_train)\n",
    "    model = train_and_accurary_model(model, x_train, y_train, x_test, y_test)\n",
    "    model_save(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LTSM version\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import sklearn.model_selection\n",
    "\n",
    "# can you drop accx, accy, and accz?\n",
    "x = np.array(df.drop(['Label'], 1)) #drops row 'Label'\n",
    "y = np.array(df[\"Label\"])\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.3)\n",
    "y_train = np.array(y_train).reshape(-1,1) # (-1,1) because our data has a single feature, and a 'n' amount of rows\n",
    "\n",
    "#build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#reshape the features for the LSTM layer\n",
    "x_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "\n",
    "#reshape the testing data\n",
    "y_test = np.array(y_test).reshape(-1,1) # (-1,1) bec  ause our data has a single feature, and a 'n' amount of rows\n",
    "x_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "#train the model\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=64, verbose=1, validation_split = 0.2)\n",
    "\n",
    "test_loss, test_Acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_Acc)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a path for the saved model to the current directory\n",
    "os.makedirs('./saved_model', exist_ok=True)\n",
    "model.save('./saved_model/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Old Version \n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# build a neural network that uses the fft of the accelerometer data to predict the label\n",
    "model = Sequential()\n",
    "#flatten the input to a 1D array\n",
    "model.add(Dense(64, activation='relu', input_shape=(x.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=20, batch_size= 20, validation_split=0.2)\n",
    "#evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "#print model summary\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919ada50126e9b7679f5f5dbe18aa91f971b460080d3011effa906ebff41bb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
