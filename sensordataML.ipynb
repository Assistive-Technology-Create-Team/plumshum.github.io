{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure all packages are installed\n",
    "\n",
    "*    pip install numpy\n",
    "*   pip install pandas\n",
    "*   pip install os-sys\n",
    "*    pip install matplotlib\n",
    "*   pip install seaborn\n",
    "*   pip install scikit-learn\n",
    "*   pip install keras\n",
    "*   pip install tensorflow*\n",
    "\n",
    "2. Collected Data from sensor py to this file "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Issues:\n",
    " * Should AccelerationX, Y, Z still be kept in dataframe?\n",
    "    inputshape is 7, not 5 \n",
    " * not sure why we have to reshape features twice \n",
    " * need cat.codes and Label_Encoder, or just one?\n",
    " * would y.to_categorical be better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/harnoor343/fall-detection-accelerometer-data\n",
    "#Link to chen hua min's code: https://www.kaggle.com/code/mmttdebbcc/notebook9689a93a64  \n",
    "# create a new directory called 'kaggle_normalized', ignore it if it already exists\n",
    "os.makedirs('./normalized', exist_ok=True)\n",
    "\n",
    "labels = ['runfall', 'downSit', 'freeFall', 'runSit', 'walkFall', 'walkSit']\n",
    "for label in labels:\n",
    "    #read all csv files in the director \"./kaggle_data/\" + l, delimit by ';'\n",
    "    #this is different from chen human min project\n",
    "    files = glob.glob('./archive/' + label + '/*.csv')\n",
    "    #assign l to to df column 'Label'\n",
    "    df = pd.concat([pd.read_csv(f, sep=';') for f in files], ignore_index=True)\n",
    "    # assign l to df column 'Label'\n",
    "    df['Label'] = label\n",
    "    # save columns 'DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label' to a new csv file\n",
    "    df[['DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label']].to_csv('./normalized/' + label + '.csv', index=False)\n",
    "\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('./normalized/*.csv')], ignore_index = True)\n",
    "columns = ['DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ', 'Label']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for each column in 'Accerlation', 'AccelerationY', 'AccelerationZ', and a new column that is the fft of the original column\n",
    "for c in ['AccelerationX', 'AccelerationY', 'AccelerationZ']:\n",
    "    df[c + '_fft'] = np.fft.fft(df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 100 column 'AccelerationX' and 'AccelerationX_fft'\n",
    "df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].iloc[:100].plot()\n",
    "\n",
    "# Versus Head (the same)\n",
    "#df[['AccelerationX_fft', 'AccelerationY_fft', 'AccelerationZ_fft']].head(100).plot()\n",
    "df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].head(100).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging Code (Mardown Text)\n",
    "\n",
    " print the shape of the dataframe\n",
    "\n",
    "              print(df.shape) \n",
    "\n",
    " print each column's name in the dataframe\n",
    " \n",
    "              print(df.columns)\n",
    "\n",
    "(202599, 8)\n",
    "Index(['DeviceOrientation', 'AccelerationX', 'AccelerationY', 'AccelerationZ',\n",
    "       'Label', 'AccelerationX_fft', 'AccelerationY_fft', 'AccelerationZ_fft'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to numerical data\n",
    "df['Label'] = df['Label'].astype('category')\n",
    "df['Label'] = df['Label'].cat.codes\n",
    "# df.head()\n",
    "\n",
    "# convert column `DeviceOrientation` to numerical data\n",
    "df['DeviceOrientation'] = df['DeviceOrientation'].astype('category')\n",
    "df['DeviceOrientation'] = df['DeviceOrientation'].cat.codes\n",
    "df.head()\n",
    "\n",
    "x = np.array(df.drop(['Label'], 1)) #drops row 'Label'\n",
    "y = np.array(df[\"Label\"])\n",
    "\n",
    "import sklearn.model_selection\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LTSM version\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode the target. \n",
    "encoder = LabelEncoder()\n",
    "    #LabelEncoder encodes Encode target labels with value between 0 and n_classes-1.\n",
    "    # This transformer should be used to encode target values, *i.e.* y, and not the input X\n",
    "encoder.fit(y_train)\n",
    "target = encoder.transform(y_train) #tranform to normalised encoding \n",
    "target = np.array(target).reshape(-1,1) # (-1,1) because our data has a single feature, and a 'n' amount of rows\n",
    "print(target)\n",
    "\n",
    "#build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#reshape the features for the LSTM layer\n",
    "# don't completely understand this part\n",
    "features = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "#x_train.shape:  141819  x_train.shape[1]:  7  1:  1\n",
    "\n",
    "#train the model\n",
    "model.fit(features, target, epochs=1, batch_size=20, verbose=1, validation_split = 0.2)\n",
    "\n",
    "test_loss, test_Acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_Acc)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.6795163154602051 \n",
    "batch_Size = 24 epochs = 15\n",
    "batch_Size = 20, epochs = 20, two new Relu layers\n",
    "validation_split = 0.1\n",
    "epochs = 25, batch_Size = 15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919ada50126e9b7679f5f5dbe18aa91f971b460080d3011effa906ebff41bb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
