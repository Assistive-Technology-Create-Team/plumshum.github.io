{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure all packages are installed\n",
    "pip install numpy\n",
    "pip install pandas\n",
    "pip install os-sys\n",
    "pip install matplotlib\n",
    "pip install seaborn\n",
    "pip install scikit-learn\n",
    "\n",
    "2. Collected Data from sensor py to this file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "glob() missing 1 required positional argument: 'pathname'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m labels \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mwalk\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstand\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfall\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m labels:\n\u001b[0;32m      4\u001b[0m     \u001b[39m#read all csv files in the directory 'kaggle_data' + l, delimit by ';'\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pd\u001b[39m.\u001b[39mread_csv(f, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39;49mglob()], ignore_index \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     \u001b[39m#assign 1 to df column 'Label'\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: glob() missing 1 required positional argument: 'pathname'"
     ]
    }
   ],
   "source": [
    "labels = [\"walk\", \"sit\", \"stand\", \"fall\"]\n",
    "\n",
    "for l in labels:\n",
    "    #read all csv files in the directory 'kaggle_data' + l, delimit by ';'\n",
    "    df = pd.concat([pd.read_csv(f, sep=';') for f in glob.glob('C:\\Users\\siyuz\\Documents\\GitHub\\plumshum.github.io\\sensordata.py')], ignore_index = True)\n",
    "    #assign 1 to df column 'Label'\n",
    "    df['Label'] = 1\n",
    "    # save columns 'DeviceOrientation', 'AccelerationX','AccelerationY', 'AccelerationZ', 'Label' to csv \n",
    "    # for kaggle normalized \n",
    "    df[['DeviceOrientation', 'AccelerationX','AccelerationY', 'AccelerationZ', 'Label']].to_csv('sensor' + l + '.csv', index=False)\n",
    "\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('./sensor_normalized/*.csv')], ignore_index = True)\n",
    "columns = ['DeviceOrientation', 'AccelerationX','AccelerationY', 'AccelerationZ', 'Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each column in 'Accerlation', 'AccelerationY', 'AccelerationZ', and a new column that is the fft of the original column\n",
    "for c in ['AccelerationX', 'AccelerationY', 'AccelerationZ']:\n",
    "    df[c + '_fft'] = np.fft.fft(df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 100 column 'AccelerationX' and 'AccelerationX_fft'\n",
    "# Hannahs Comment: AI does not recgonize the first fft of ____ I think, so just rewrite\n",
    "df[['AccelerationX_fft', 'AccelerationY_fft', 'AccelerationZ_fft']].iloc[:100].plot()\n",
    "df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].iloc[:100].plot()\n",
    "\n",
    "# Versus Head (the same)\n",
    "\n",
    "df[['AccelerationX_fft', 'AccelerationY_fft', 'AccelerationZ_fft']].head(100).plot()\n",
    "df[['AccelerationX', 'AccelerationY', 'AccelerationZ']].head(100).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column 'DeviceOreignation' to one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['DeviceOrientation'])\n",
    "x = np.array(df.drop(['Label'], axis=1))\n",
    "y = np.array(df['Label'])\n",
    "\n",
    "print(x)\n",
    "#normalize the data\n",
    "import sklearn.model_selection as model_selection\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "# Hannah's Comment my AI added random_state = 42; Makes sure that the randomizness works well or something I forgot\n",
    "# Hannah's Comment: the +0.j is a because the data is shown as a complex number"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919ada50126e9b7679f5f5dbe18aa91f971b460080d3011effa906ebff41bb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
