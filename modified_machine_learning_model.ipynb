{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Assistive-Technology-Create-Team/plumshum.github.io/blob/new_data_acquisition_and_machine_learning/modified_machine_learning_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use this [FallALlID2.csv file](https://drive.google.com/file/d/1Oi4Y_-EtZxU9mOAn-v5a93EDW43gpS1n/view?usp=sharing). Make sure to upload your own version to your Google Drive. \n",
        "\n",
        "1. Install Packages\n",
        "2. Mount Drive\n",
        "3. Change Google Colab Runtime to use GPU"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s8fMTFViRlwm"
      },
      "source": [
        "4. Run All the remaining cells except for the last one.\n",
        "5. The 3rd to last cell has a line\n",
        "\n",
        "```\n",
        "var = 0\n",
        "x_train, x_test, y_train, y_test = data_split(df, var)\n",
        "```\n",
        "   and the 2nd to alst cell has a line\n",
        "```\n",
        "model = train_and_accurary_model(model, x_train, x_test, y_train, y_test, var)\n",
        "\n",
        "```\n",
        "Every time you finish training a model, change the variable `var` by 1 until 6. `var` represent a different amount of features used. \n",
        "\n",
        "6. Every time a model is saved, it should be saved in your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfImyuhHOOiU"
      },
      "outputs": [],
      "source": [
        "#Run to install packages. Will take a few minutes\n",
        "%pip install numpy\n",
        "%pip install pandas\n",
        "%pip install os-sys\n",
        "%pip install matplotlib\n",
        "%pip install seaborn\n",
        "%pip install scikit-learn\n",
        "%pip install \"tensorflow-gpu<2.10\"\n",
        "%pip install \"tensorflow<2.10\"\n",
        "%pip install \"keras<2.10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoZIOzMROOiV",
        "outputId": "882e7e08-f2b4-4b1b-ed5c-7c5c051f10db"
      },
      "outputs": [],
      "source": [
        "# If you are on Google Colab run this\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFTtpuwdOOiW",
        "outputId": "07f2173f-ca4a-4ddf-9254-708d2be10bdd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn \n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "import sklearn.model_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#If you do not see 1 Physical GPUs, 1 Logical GPUs, then you are most likely not using a GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CYuuRh9IOOiW"
      },
      "outputs": [],
      "source": [
        "def data_collection():\n",
        "\n",
        "    # import csv file\n",
        "    # ON GOOGLE COLAB\n",
        "        # read csv file from your google drive. find the file in your drive and copy the path and replace\n",
        "        # the path in the read_csv function with the path to your file\n",
        "    df = pd.read_csv('FallAllD2.csv')\n",
        "    # convert all columns to float32\n",
        "    df = df.astype('float32')\n",
        "    print(\"finished collecting data\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fKM-0yEYOOiX"
      },
      "outputs": [],
      "source": [
        "def data_label(df):\n",
        "    # add a new column called \"IsFall\" that is 1 if the ActivityID > 100, and 0 if it is not\n",
        "    df['IsFall'] = df['ActivityID'].apply(lambda x: 1 if x > 100 else 0)\n",
        "    return df\n",
        "\n",
        "def data_split(df, num):\n",
        "    df = data_label(df)\n",
        "    x = df[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "    # split the data into features and labels\n",
        "    if num == 0: x = df[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "    elif num == 1: x = df[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z']]\n",
        "    elif num == 2: x = df[['Device','Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "    elif num == 3: x = df[['Device','Acc_x','Acc_y','Acc_z', 'Bar_x', 'Bar_y']]\n",
        "    elif num == 4: x = df[['Device','Acc_x','Acc_y','Acc_z']]\n",
        "    elif num == 5: x = df[['Device','Gyr_x', 'Gyr_y', 'Gyr_z']]\n",
        "    elif num == 6: x = df[['Device','Bar_x', 'Bar_y']]\n",
        "    y = df['IsFall']\n",
        "\n",
        "    #print(\"x is:\", x)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    x = scaler.fit_transform(x)\n",
        "    x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
        "    \n",
        "    #Spliting Data\n",
        "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size = 0.2)\n",
        "    print('x y shape: ', x_train.shape, y_train.shape)\n",
        "\n",
        "    print(\"data split\")\n",
        "\n",
        "    return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GTyAtgZ0OOiY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def model_create(x_train, layer1_input = 512, layer2_input = 128):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(layer1_input, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "  model.add(Dropout(0.2))\n",
        "  \n",
        "  # add a Flatten layer using x_train as input shape\n",
        "  #model.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "\n",
        "  model.add(Dense(layer2_input, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  # for activity classification, we need 136 neurons in the output layer and categorical crossentropy as the loss function\n",
        "  #model.add(Dense(136, activation='softmax'))\n",
        "  #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  # for IsFall classification, we need 1 neuron in the output layer and binary crossentropy as the loss function\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def train_and_accurary_model(model, x_train, x_test, y_train, y_test, num):\n",
        "\n",
        "  # train the model\n",
        "  model.fit(x_train, y_train, epochs=10, batch_size=256, validation_split=0.1)\n",
        "\n",
        "  # evaluate the model\n",
        "  test_loss, test_Acc = model.evaluate(x_test, y_test)\n",
        "  print('Test accuracy:', test_Acc)\n",
        "  model.summary()\n",
        "  print(\"Confusion Matrix\")\n",
        "  y_pred = model.predict(x_test)\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  confusion_mtx = confusion_matrix(y_test, y_pred)\n",
        "  confusion_mtx_percent = confusion_mtx / confusion_mtx.sum(axis=1)[:, np.newaxis]\n",
        "  print(confusion_mtx_percent)\n",
        "\n",
        "  # Save Model to Local Machine\n",
        "  file_name = 'model' + str(num) + '_device2_aggregate.h5'\n",
        "\n",
        "  model.save(file_name)\n",
        "  #from google.colab import files\n",
        "  #files.download(file_name)\n",
        "  print(\"Model downloaded to local machine\")\n",
        "\n",
        "  # Save Model to Google Drive\n",
        "  #model.save('/content/drive/My Drive/' + file_name )\n",
        "  #print(\"ModelÂ saved to Google Drive\")\n",
        "  \n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = data_collection()\n",
        "original_df = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = original_df.copy()\n",
        "\n",
        "# find the range of Bar_x\n",
        "print(df['Bar_x'].min(), df['Bar_x'].max())\n",
        "# drop all rows where Bar_x is 'nan'\n",
        "df = df[df['Bar_x'].notna()]\n",
        "# keep a copy of df\n",
        "df_copy = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df_copy.copy()\n",
        "# 1: Neck, 2: Wrist, 3: Waist\n",
        "df = df[df['Device'] == 2]\n",
        "\n",
        "var = 0 # change this number from 0 - 6\n",
        "x_train, x_test, y_train, y_test = data_split(df, var) \n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ommited One Code Cell. Seemed Repetitive\n",
        "```\n",
        "df = df_copy.copy()\n",
        "# 1: Neck, 2: Wrist, 3: Waist\n",
        "df = df[df['Device'] == 2]\n",
        "\n",
        "var = 0 #change this number from 0 - 6\n",
        "x_train, x_test, y_train, y_test = data_split(df, var) \n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "# Create and Train Model\n",
        "teacher_model = model_create(x_train)\n",
        "print(\"Model Created\")\n",
        "teacher_model = train_and_accurary_model(teacher_model, x_train, x_test, y_train, y_test, var)\n",
        "print(\"Model Trained\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and Train Teacher model Model\n",
        "teacher_model = model_create(x_train, layer1_input=256, layer2_input=64)\n",
        "print(\"Model Created\")\n",
        "teacher_model = train_and_accurary_model(teacher_model, x_train, x_test, y_train, y_test, var)\n",
        "print(\"Model Trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_acc = df_copy.copy()\n",
        "df_acc = df_acc[df_acc['Device'] == 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def student_data_split(df, num):\n",
        "    df = data_label(df)\n",
        "    x = df[['Device','Acc_x','Acc_y','Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z', 'Bar_x', 'Bar_y']]\n",
        "    \n",
        "    if num == 1: \n",
        "        # set 'Bar_x' and 'Bar_y' to 0\n",
        "        df['Bar_x'] = 0\n",
        "        df['Bar_y'] = 0\n",
        "\n",
        "    if num == 2: \n",
        "        # set 'Acc_x', 'Acc_y', 'Acc_z' to 0\n",
        "        df['Acc_x'] = 0\n",
        "        df['Acc_y'] = 0\n",
        "        df['Acc_z'] = 0\n",
        "\n",
        "    if num == 3:\n",
        "        # set 'Gyr_x', 'Gyr_y', 'Gyr_z' to 0\n",
        "        df['Gyr_x'] = 0\n",
        "        df['Gyr_y'] = 0\n",
        "        df['Gyr_z'] = 0\n",
        "    \n",
        "    if num == 4:\n",
        "        # set 'Bar_x' and 'Bar_y' to 0\n",
        "        df['Bar_x'] = 0\n",
        "        df['Bar_y'] = 0\n",
        "        # set 'Gyr_x', 'Gyr_y', 'Gyr_z' to 0\n",
        "        df['Gyr_x'] = 0\n",
        "        df['Gyr_y'] = 0\n",
        "        df['Gyr_z'] = 0\n",
        "    \n",
        "    if num == 5:\n",
        "        # set 'Bar_x' and 'Bar_y' to 0\n",
        "        df['Bar_x'] = 0\n",
        "        df['Bar_y'] = 0\n",
        "        # set 'Acc_x', 'Acc_y', 'Acc_z' to 0\n",
        "        df['Acc_x'] = 0\n",
        "        df['Acc_y'] = 0\n",
        "        df['Acc_z'] = 0\n",
        "\n",
        "    if num == 6:\n",
        "        # set 'Gyr_x', 'Gyr_y', 'Gyr_z' to 0\n",
        "        df['Gyr_x'] = 0\n",
        "        df['Gyr_y'] = 0\n",
        "        df['Gyr_z'] = 0\n",
        "        # set 'Acc_x', 'Acc_y', 'Acc_z' to 0\n",
        "        df['Acc_x'] = 0\n",
        "        df['Acc_y'] = 0\n",
        "        df['Acc_z'] = 0\n",
        "\n",
        "    scaler = StandardScarler()\n",
        "    x = scaler.fit_transform(x)\n",
        "    x = x.reshape(x.shape[0], 1, x.shape[1])\n",
        "\n",
        "    #convert df to float32\n",
        "    df = df.astype('float32')\n",
        "\n",
        "    y = df['IsFall']\n",
        "\n",
        "    #Splitting Data\n",
        "    x_train, x_test, y_train, y_test =sklearn.model_selection.train_test_split(x,y,test_size = 0.2)  \n",
        "\n",
        "var = 6\n",
        "student_x_train, student_x_test, student_y_train, student_y_test = student_data_split(df_acc, var) \n",
        "print(student_x_train.shape, student_y_train.shape)\n",
        "print(student_x_test.shape, student_y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Knowledge distillation\n",
        "temperature = 5.0\n",
        "teacher_logits = tf.keras.layers.Lambda(lambda x: x / temperature)(teacher_model.layers[-2].output)\n",
        "teacher_model_logits = tf.keras.models.Model(teacher_model.inputs, teacher_logits)\n",
        "\n",
        "# Function to create a knowledge distillation loss\n",
        "def knowledge_distillation_loss(y_true, y_pred_logits):\n",
        "    y_pred = tf.nn.sigmoid(y_pred_logits / temperature)\n",
        "    y_true = tf.nn.sigmoid(y_true / temperature)\n",
        "    return KLDivergence()(y_true, y_pred)\n",
        "\n",
        "# Custom loss function that combines knowledge distillation loss and the original binary crossentropy loss\n",
        "def combined_loss(y_true, y_pred):\n",
        "    kd_loss = knowledge_distillation_loss(y_true, y_pred)\n",
        "    original_loss = BinaryCrossentropy(from_logits=True)(y_true, y_pred)\n",
        "    return kd_loss + original_loss\n",
        "\n",
        "student_model = Sequential()\n",
        "student_model.add(LSTM(256, input_shape=(student_x_train.shape[1], student_x_train.shape[2])))\n",
        "student_model.add(Dropout(0.2))\n",
        "student_model.add(Dense(64, activation='relu'))\n",
        "student_model.add(Dropout(0.3))\n",
        "student_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "student_model.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])\n",
        "\n",
        "student_model.fit(student_x_train, student_y_train, epochs=2, batch_size=256, validation_split=0.1)\n",
        "\n",
        "# evaluate the model\n",
        "test_loss, test_Acc = student_model.evaluate(student_x_test, student_y_test)\n",
        "print('Test accuracy:', test_Acc)\n",
        "#student_model.summary()\n",
        "#print(\"Confusion Matrix\")\n",
        "y_pred = student_model.predict(student_x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "confusion_mtx = confusion_matrix(student_y_test, y_pred)\n",
        "confusion_mtx_percent = confusion_mtx / confusion_mtx.sum(axis=1)[:, np.newaxis]\n",
        "#print(confusion_mtx_percent)\n",
        "\n",
        "# Save Model to Local Machine\n",
        "file_name = 'student_model' + str(var) + '_device2_aggregate.h5'\n",
        "\n",
        "student_model.save(file_name)\n",
        "#from google.colab import files\n",
        "#files.download(file_name)  # Download to local machine\n",
        "print(\"Model downloaded to local machine\")\n",
        "\n",
        "print(\"Student Model Trained\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS04lWctRwbb"
      },
      "source": [
        "Do not run the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApXk4OasOOiY"
      },
      "outputs": [],
      "source": [
        "# CODE DOESN'T WORK YET\n",
        "# Get model from folder all_models. take model summaries and put them into a txt file. download txt file to local machine\n",
        "def get_model_summaries():\n",
        "    import os\n",
        "    from keras.models import load_model\n",
        "    from keras.utils.vis_utils import plot_model\n",
        "    from keras.utils import print_summary\n",
        "    \n",
        "    # get all files in the folder\n",
        "    files = os.listdir('all models')\n",
        "    print(files)\n",
        "    \n",
        "    # open a file to write the model summaries to\n",
        "    f = open(\"model_summaries.txt\", \"w\")\n",
        "    \n",
        "    # loop through all files in the folder\n",
        "    for file in files:\n",
        "        # load the model\n",
        "        model = load_model('all_models/' + file)\n",
        "        # get the model summary\n",
        "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "        # get the model plot\n",
        "        plot_model(model, to_file='model_plots/' + file + '.png', show_shapes=True, show_layer_names=True)\n",
        "        # write a line break\n",
        "        f.write('\\n\\n')\n",
        "    f.close()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create table with row for models, and column for accuracy\n",
        "# create a table with 7 rows and 1 column\n",
        "table = np.zeros((7,1))\n",
        "# create a dataframe with the table\n",
        "df = pd.DataFrame(table, columns=['Accuracy'])\n",
        "# add a column called \"Model\" with the model numbers\n",
        "df['Model'] = ['ABG', 'AG', 'GB', 'AB','A', 'G', 'B']\n",
        "# set the index to be the \"Model\" column\n",
        "df = df.set_index('Model')\n",
        "df['Accuracy'] = [0.9933268427848816,\n",
        "                  0.8989095091819763,\n",
        "                  0.967968761920929,\n",
        "                  0.9861978888511658,\n",
        "                  0.8534993529319763,\n",
        "                  0.8021810054779053,\n",
        "                  0.9472493529319763]\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "919ada50126e9b7679f5f5dbe18aa91f971b460080d3011effa906ebff41bb2e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
